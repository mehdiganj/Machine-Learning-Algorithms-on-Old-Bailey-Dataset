{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron implementation:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing panda and numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset and converting as panda framework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data (filename):\n",
    "    \"\"\"\n",
    "    This function, imports the train/test data and create the attribute matrix and labels using the input data\n",
    "    \"\"\"\n",
    "    Matrix = []\n",
    "    Label = []\n",
    "    with open(filename) as f:\n",
    "\n",
    "        for line in f:\n",
    "            sample = line.split()\n",
    "            Label.append(float(sample[0]))\n",
    "            sample.pop(0)\n",
    "            row = []\n",
    "            for s in sample:\n",
    "                feature, value = s.split(':')\n",
    "                z = len(row)\n",
    "                nz = int(feature) - (z+1)\n",
    "                for i in range (nz):\n",
    "                    row.append(0)\n",
    "                row.append(float(value))\n",
    "            Matrix.append(row)\n",
    "    data =[]\n",
    "    M = max(len(row) for row in Matrix)\n",
    "    #print(\"M:\",M)\n",
    "    for row in Matrix:\n",
    "        nz = M - (len(row))\n",
    "        for i in range (nz):\n",
    "            row.append(0)\n",
    "        data.append(row)\n",
    "    Label1 = np.array(Label)\n",
    "    data1= np.array(data)\n",
    "    #print(\"aaa:\",Label1, data1.shape)\n",
    "    S1 = np.concatenate((data1, Label1[:,None]),axis=1)\n",
    "    attributes = np.arange(1, np.size(data1,1)+2)\n",
    "    #print(attributes)\n",
    "    samples = range(0,np.size(data1,0))\n",
    "    data2 = pd.DataFrame(S1, columns=attributes, index=samples)\n",
    "    #print('label',data2[6])\n",
    "\n",
    "    return data2\n",
    "    #print(\"data1:\",data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_label(D):\n",
    "    x,y = D.shape\n",
    "    for i in range(x):\n",
    "        if D[y][i] ==0.0:\n",
    "            D[y][i] = -1.0\n",
    "    return (D)\n",
    "def k_fold(D,k):\n",
    "    cols = D.columns\n",
    "    D = D.to_numpy()\n",
    "    r_n, _ = D.shape\n",
    "    k_n = (r_n//5)\n",
    "    lb = (k-1)*k_n\n",
    "    if k == 5:\n",
    "        ub = r_n\n",
    "    else:\n",
    "        ub = k*k_n-1\n",
    "    \n",
    "    fk = D [lb:ub, :] \n",
    "    \n",
    "    Fk = pd.DataFrame(fk, columns=cols)\n",
    "    return Fk\n",
    "\n",
    "def import_label (D, new_feature):\n",
    "    D = D.to_numpy()\n",
    "    D = D.copy()\n",
    "    new_feature = new_feature.to_numpy()\n",
    "    labels = D[:, -1]\n",
    "    labels = labels[:,None]\n",
    "\n",
    "    D_out = np.append(new_feature, labels, axis=1)\n",
    "    \n",
    "    attributes = np.arange(1, np.size(D_out,1)+1)\n",
    "    D_out = pd.DataFrame(D_out, columns=attributes)\n",
    "    return D_out\n",
    "\n",
    "def concat_datasets (D1, D2):\n",
    "    if type(D1) != np.ndarray:\n",
    "        D1 = D1.to_numpy()\n",
    "    if type(D2) != np.ndarray:\n",
    "        D2 = D2.to_numpy()\n",
    "    D1 = D1.copy()\n",
    "    D_out = np.append(D1[:,:-1], D2, axis=1)\n",
    "    \n",
    "    attributes = np.arange(1, np.size(D_out,1)+1)\n",
    "    D_out = pd.DataFrame(D_out, columns=attributes)\n",
    "    return D_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the glove datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data1 = import_data('glove.train.libsvm')\n",
    "Train_data_glove = update_label(Train_data1)\n",
    "Test_data1 = import_data('glove.test.libsvm')\n",
    "Test_data_glove = update_label(Test_data1)\n",
    "Eval_data_glove = import_data('glove.eval.anon.libsvm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the bag of words datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data1 = import_data('bow.train.libsvm')\n",
    "Train_data_bow = update_label(Train_data1)\n",
    "Test_data1 = import_data('bow.test.libsvm')\n",
    "Test_data_bow = update_label(Test_data1)\n",
    "Eval_data_bow = import_data('bow.eval.anon.libsvm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the tfidf datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data1 = import_data('tfidf.train.libsvm')\n",
    "Train_data_tfidf = update_label(Train_data1)\n",
    "Test_data1 = import_data('tfidf.test.libsvm')\n",
    "Test_data_tfidf = update_label(Test_data1)\n",
    "Eval_data_tfidf = import_data('tfidf.eval.anon.libsvm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the miscellaneous datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "misc_train = pd.read_csv ('misc-attributes-train.csv')\n",
    "train_samples, _ = misc_train.shape\n",
    "misc_test = pd.read_csv ('misc-attributes-test.csv')\n",
    "test_samples, _ = misc_test.shape\n",
    "misc_eval = pd.read_csv ('misc-attributes-eval.csv')\n",
    "eval_samples, _ = misc_eval.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In order to convert the database to one hot encoding, all the dataset are concatenated and converted to correlate the cominations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>defendant_age</th>\n",
       "      <th>defendant_gender</th>\n",
       "      <th>num_victims</th>\n",
       "      <th>victim_genders</th>\n",
       "      <th>offence_category</th>\n",
       "      <th>offence_subcategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>theft</td>\n",
       "      <td>theftFromPlace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>theft</td>\n",
       "      <td>pocketpicking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>not known</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>theft</td>\n",
       "      <td>pocketpicking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>not known</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>theft</td>\n",
       "      <td>simpleLarceny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>theft</td>\n",
       "      <td>pocketpicking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  defendant_age defendant_gender  num_victims victim_genders offence_category  \\\n",
       "0            62           female            1           male            theft   \n",
       "1            17             male            1           male            theft   \n",
       "2     not known             male            1           male            theft   \n",
       "3     not known             male            1           male            theft   \n",
       "4            52             male            1         female            theft   \n",
       "\n",
       "  offence_subcategory  \n",
       "0      theftFromPlace  \n",
       "1       pocketpicking  \n",
       "2       pocketpicking  \n",
       "3       simpleLarceny  \n",
       "4       pocketpicking  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database = pd.concat([misc_train, misc_test, misc_eval], axis=0)\n",
    "database.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defendant_age          object\n",
       "defendant_gender       object\n",
       "num_victims             int64\n",
       "victim_genders         object\n",
       "offence_category       object\n",
       "offence_subcategory    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>defendant_age</th>\n",
       "      <th>defendant_gender</th>\n",
       "      <th>num_victims</th>\n",
       "      <th>victim_genders</th>\n",
       "      <th>offence_category</th>\n",
       "      <th>offence_subcategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>theft</td>\n",
       "      <td>theftFromPlace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>theft</td>\n",
       "      <td>pocketpicking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>theft</td>\n",
       "      <td>pocketpicking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>theft</td>\n",
       "      <td>simpleLarceny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>theft</td>\n",
       "      <td>pocketpicking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>theft</td>\n",
       "      <td>theftFromPlace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>no_gender</td>\n",
       "      <td>sexual</td>\n",
       "      <td>sodomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>theft</td>\n",
       "      <td>stealingFromMaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5248</td>\n",
       "      <td>26.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>theft</td>\n",
       "      <td>burglary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5249</td>\n",
       "      <td>16.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>theft</td>\n",
       "      <td>simpleLarceny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      defendant_age defendant_gender  num_victims victim_genders  \\\n",
       "0              62.0           female            1           male   \n",
       "1              17.0             male            1           male   \n",
       "2               0.0             male            1           male   \n",
       "3               0.0             male            1           male   \n",
       "4              52.0             male            1         female   \n",
       "...             ...              ...          ...            ...   \n",
       "5245            0.0             male            1           male   \n",
       "5246            0.0             male            0      no_gender   \n",
       "5247            0.0             male            1           male   \n",
       "5248           26.0             male            1           male   \n",
       "5249           16.0             male            1         female   \n",
       "\n",
       "     offence_category offence_subcategory  \n",
       "0               theft      theftFromPlace  \n",
       "1               theft       pocketpicking  \n",
       "2               theft       pocketpicking  \n",
       "3               theft       simpleLarceny  \n",
       "4               theft       pocketpicking  \n",
       "...               ...                 ...  \n",
       "5245            theft      theftFromPlace  \n",
       "5246           sexual              sodomy  \n",
       "5247            theft  stealingFromMaster  \n",
       "5248            theft            burglary  \n",
       "5249            theft       simpleLarceny  \n",
       "\n",
       "[25000 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database[database.isnull().any(axis=1)]\n",
    "# Converting \"NaN\" to no_gender in victom_genders category:\n",
    "database = database.fillna({\"victim_genders\": \"no_gender\"})\n",
    "database.head()\n",
    "\n",
    "# convert all string data in defendant such as not known ,... to Nan and then substitute nan with 0;\n",
    "database['defendant_age'] = pd.to_numeric(database.defendant_age, errors='coerce')\n",
    "database = database.fillna({\"defendant_age\": 0})\n",
    "database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that all the data are free of Nan we can convert them to one-hot encoding.\n",
    "misc_transfered = pd.concat([database.defendant_age, database.num_victims, pd.get_dummies(database.defendant_gender), pd.get_dummies(database.victim_genders), pd.get_dummies(database.offence_category), pd.get_dummies(database.offence_subcategory)], axis=1)\n",
    "# for dicision tree i convert all of the featres to one-hot encoding\n",
    "misc_transfered_all_bin = pd.concat([pd.get_dummies(database.defendant_age), pd.get_dummies(database.num_victims), pd.get_dummies(database.defendant_gender), pd.get_dummies(database.victim_genders), pd.get_dummies(database.offence_category), pd.get_dummies(database.offence_subcategory)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>defendant_age</th>\n",
       "      <th>num_victims</th>\n",
       "      <th>female</th>\n",
       "      <th>indeterminate</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>female;female</th>\n",
       "      <th>female;female;female</th>\n",
       "      <th>female;female;female;female</th>\n",
       "      <th>female;female;female;female;female</th>\n",
       "      <th>...</th>\n",
       "      <th>shoplifting</th>\n",
       "      <th>simpleLarceny</th>\n",
       "      <th>sodomy</th>\n",
       "      <th>stealingFromMaster</th>\n",
       "      <th>taxOffences</th>\n",
       "      <th>theftFromPlace</th>\n",
       "      <th>threateningBehaviour</th>\n",
       "      <th>treason</th>\n",
       "      <th>vagabond</th>\n",
       "      <th>wounding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5248</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5249</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      defendant_age  num_victims  female  indeterminate  male  female  \\\n",
       "0              62.0            1       1              0     0       0   \n",
       "1              17.0            1       0              0     1       0   \n",
       "2               0.0            1       0              0     1       0   \n",
       "3               0.0            1       0              0     1       0   \n",
       "4              52.0            1       0              0     1       1   \n",
       "...             ...          ...     ...            ...   ...     ...   \n",
       "5245            0.0            1       0              0     1       0   \n",
       "5246            0.0            0       0              0     1       0   \n",
       "5247            0.0            1       0              0     1       0   \n",
       "5248           26.0            1       0              0     1       0   \n",
       "5249           16.0            1       0              0     1       1   \n",
       "\n",
       "      female;female  female;female;female  female;female;female;female  \\\n",
       "0                 0                     0                            0   \n",
       "1                 0                     0                            0   \n",
       "2                 0                     0                            0   \n",
       "3                 0                     0                            0   \n",
       "4                 0                     0                            0   \n",
       "...             ...                   ...                          ...   \n",
       "5245              0                     0                            0   \n",
       "5246              0                     0                            0   \n",
       "5247              0                     0                            0   \n",
       "5248              0                     0                            0   \n",
       "5249              0                     0                            0   \n",
       "\n",
       "      female;female;female;female;female  ...  shoplifting  simpleLarceny  \\\n",
       "0                                      0  ...            0              0   \n",
       "1                                      0  ...            0              0   \n",
       "2                                      0  ...            0              0   \n",
       "3                                      0  ...            0              1   \n",
       "4                                      0  ...            0              0   \n",
       "...                                  ...  ...          ...            ...   \n",
       "5245                                   0  ...            0              0   \n",
       "5246                                   0  ...            0              0   \n",
       "5247                                   0  ...            0              0   \n",
       "5248                                   0  ...            0              0   \n",
       "5249                                   0  ...            0              1   \n",
       "\n",
       "      sodomy  stealingFromMaster  taxOffences  theftFromPlace  \\\n",
       "0          0                   0            0               1   \n",
       "1          0                   0            0               0   \n",
       "2          0                   0            0               0   \n",
       "3          0                   0            0               0   \n",
       "4          0                   0            0               0   \n",
       "...      ...                 ...          ...             ...   \n",
       "5245       0                   0            0               1   \n",
       "5246       1                   0            0               0   \n",
       "5247       0                   1            0               0   \n",
       "5248       0                   0            0               0   \n",
       "5249       0                   0            0               0   \n",
       "\n",
       "      threateningBehaviour  treason  vagabond  wounding  \n",
       "0                        0        0         0         0  \n",
       "1                        0        0         0         0  \n",
       "2                        0        0         0         0  \n",
       "3                        0        0         0         0  \n",
       "4                        0        0         0         0  \n",
       "...                    ...      ...       ...       ...  \n",
       "5245                     0        0         0         0  \n",
       "5246                     0        0         0         0  \n",
       "5247                     0        0         0         0  \n",
       "5248                     0        0         0         0  \n",
       "5249                     0        0         0         0  \n",
       "\n",
       "[25000 rows x 139 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misc_transfered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17500, 140)\n"
     ]
    }
   ],
   "source": [
    "Train_misc_transfered = misc_transfered.iloc[:train_samples,:] \n",
    "Test_misc_transfered = misc_transfered.iloc[train_samples:train_samples+test_samples,:]\n",
    "Eval_misc_transfered = misc_transfered.iloc[train_samples+test_samples:,:] \n",
    "Train_misc = import_label(Train_data_glove, Train_misc_transfered)\n",
    "Test_misc = import_label(Test_data_glove, Test_misc_transfered)\n",
    "Eval_misc = import_label(Eval_data_glove, Eval_misc_transfered)\n",
    "print(Train_misc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_ev(f1, f2, f3, f4, f5, max_epoch, learning_rate, perceptron_fcn, margin_variable = 0):\n",
    "    \"\"\"\n",
    "    The function calculates the mean accuracy and std based on the 5-fold cross validation\n",
    "    \"\"\"\n",
    "\n",
    "    #train_data = pd.DataFrame(columns = f1.columns)\n",
    "    dataset = []\n",
    "    acc = []\n",
    "   \n",
    "    for i in range (1,6):\n",
    "        valid_data = eval(\"f\"+str(i))\n",
    "        train_name =[]\n",
    "        val_name = [\"f\"+str(i)]\n",
    "        #print(i,val_name)\n",
    "        #print(valid_data)\n",
    "        for j in range(1,6):\n",
    "            if j != i:\n",
    "                #print(j)\n",
    "                train_name.append (\"f\"+str(j))\n",
    "                dataset.append(eval(\"f\"+str(j)))\n",
    "        train_data = pd.concat(dataset, ignore_index=True)\n",
    "        dataset = []\n",
    "        #print(train_data.shape)\n",
    "        #print(train_data)\n",
    "        if perceptron_fcn == 'simple_perceptron':\n",
    "            w, b, _ = perceptron(train_data, max_epoch, learning_rate)\n",
    "        elif perceptron_fcn == 'decaying_perceptron':\n",
    "            w, b, _ = perceptron_decay(train_data, max_epoch, learning_rate)\n",
    "        elif perceptron_fcn == 'average_perceptron':\n",
    "            w, b, _ = avg_perceptron(train_data, max_epoch, learning_rate)\n",
    "        elif perceptron_fcn == 'margin_perceptron':\n",
    "            w, b, _ = margin_perceptron(train_data, max_epoch, learning_rate, margin_variable)\n",
    "            \n",
    "        w = w[-1]\n",
    "        #print(w)\n",
    "        b = b [-1]\n",
    "        \n",
    "        #print(train_name)\n",
    "        acc.append (accuracy (valid_data, w,b))\n",
    "    #print(\"accuracy:\", acc)\n",
    "    Std = np.std(acc)\n",
    "    Mean = np.mean(acc)\n",
    "    \n",
    "    return Mean, Std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy (D, w, b):\n",
    "    \"\"\"\n",
    "        This function returns the accuracy of the dataset based on set D and weight and bias. \n",
    "    \"\"\"\n",
    "    D = D.to_numpy()\n",
    "    n_correct_prediction = 0\n",
    "    n_samples = np.size(D,0)\n",
    "    label_ix = np.size(D,1)\n",
    "    for i in range(n_samples):\n",
    "        sample = D[i,:]\n",
    "        true_label = sample[-1]\n",
    "        xi = sample[:-1]\n",
    "        predicted_label = np.sign (np.dot(xi,w) + b)\n",
    "        if predicted_label == true_label:\n",
    "            n_correct_prediction += 1\n",
    "    acc = n_correct_prediction/n_samples * 100\n",
    "    return acc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction (D, w, b):\n",
    "    \"\"\"\n",
    "        This function returns the prediction of the dataset based on set D and weight and bias. \n",
    "    \"\"\"\n",
    "    D = D.to_numpy()\n",
    "    n_samples = np.size(D,0)\n",
    "    label_ix = np.size(D,1)\n",
    "    pred = []\n",
    "    for i in range(n_samples):\n",
    "        sample = D[i,:]\n",
    "        xi = sample[:-1]\n",
    "        predicted_label = np.sign (np.dot(xi,w) + b)\n",
    "        #print(predicted_label[0])\n",
    "        if predicted_label == -1.0:\n",
    "            predicted_label = [0.0]\n",
    "        pred.append([i, predicted_label[0]])\n",
    "        \n",
    "    Pred = pd.DataFrame(pred, columns=['example_id', 'label'])\n",
    "\n",
    "    return Pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the folded datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " predicted label  Train accuracy(%)  Test accuracy(%)\n",
      "            -1.0          50.342857         48.844444\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def frequent_label(D):\n",
    "    \"\"\"\n",
    "    Create common label for set S:\n",
    "    \"\"\"\n",
    "    label_ix = np.size(D,1)\n",
    "    label = np.unique(D[label_ix])[np.argmax(np.unique(D[label_ix],return_counts=True)[1])]\n",
    "    \n",
    "    return label\n",
    "\n",
    "\n",
    "\n",
    "def baseline_accuracy (D, predicted_label):\n",
    "    \"\"\"\n",
    "        This function returns the baseline accuracy of the dataset for baseline. \n",
    "    \"\"\"\n",
    "    D = D.to_numpy()\n",
    "    n_correct_prediction = 0\n",
    "    n_samples = np.size(D,0)\n",
    "    label_ix = np.size(D,1)\n",
    "    for i in range(n_samples):\n",
    "        sample = D[i,:]\n",
    "        true_label = sample[-1]\n",
    "        xi = sample[:-1]\n",
    "        if predicted_label == true_label:\n",
    "            n_correct_prediction += 1\n",
    "    acc = n_correct_prediction/n_samples * 100\n",
    "    return acc\n",
    "predicted_label = frequent_label(Train_data)\n",
    "\n",
    "Train_acc = baseline_accuracy (Train_data, predicted_label)\n",
    "Test_acc = baseline_accuracy (Test_data, predicted_label)\n",
    "\n",
    "\n",
    "report1 = [{'predicted label':predicted_label, 'Train accuracy(%)':Train_acc, \n",
    "            'Test accuracy(%)':Test_acc}]\n",
    "\n",
    "report1 = pd.DataFrame.from_records(report1)\n",
    "print(report1.to_string(index = False))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Margin Perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_perceptron (D, max_epoch, learning_rate, margin_variable):\n",
    "    D = D.to_numpy()\n",
    "    #lr = learning_rate\n",
    "    u = margin_variable\n",
    "    \n",
    "     \n",
    "    w_size = np.size(D,1)-1\n",
    "    w = -.01 + 0.02 * np.random.rand(w_size)\n",
    "    ba = 0 \n",
    "    b = -.01 + 0.02 * np.random.rand(1)\n",
    "    a = 0\n",
    "    update = 0\n",
    "    ep_a = []\n",
    "    ep_ba = []\n",
    "    ep_update = []\n",
    "    #ep_w = []\n",
    "    #ep_b = []\n",
    "    #ep_update = []\n",
    "    for epoch in range(1, max_epoch+1):\n",
    "        lr = learning_rate/epoch \n",
    "        #1.shuffle the data\n",
    "        up = 0\n",
    "        \n",
    "        np.random.shuffle(D)\n",
    "        #2.Update weights:\n",
    "        for i in range (np.size(D,0)):\n",
    "            xi = D[i,:-1]\n",
    "            yi = D[i,-1]\n",
    "            if yi * (np.dot(xi, w) + b) < u:\n",
    "                update += 1\n",
    "                w += lr * yi * xi\n",
    "                b += lr * yi\n",
    "            a += w\n",
    "            ba += b\n",
    "        \n",
    "        #update.append(up)\n",
    "        #print(\"w0:\", w[0])\n",
    "        a1 = a\n",
    "        ba1 = ba\n",
    "        update1 = update\n",
    "        \n",
    "        #w1 = w\n",
    "        #b1 = b\n",
    "        #update1 = update\n",
    "        #print(b)\n",
    "        #print(b1)\n",
    "        ep_a.append(a1.copy())\n",
    "        ep_ba.append(ba1.copy())\n",
    "        ep_update.append(update1)\n",
    "        #print('ep_b:',ep_b)\n",
    "    #print('update:', update)\n",
    "    ep_a = np.array(ep_a)\n",
    "    ep_ba = np.array(ep_ba)\n",
    "    ep_update = np.array(ep_update)\n",
    "    return ep_a, ep_ba, ep_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Margin Perceptron over gloves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data1_gloves = Train_data_glove\n",
    "cols = Data1_gloves.columns\n",
    "Data1_gloves = Data1_gloves.to_numpy()\n",
    "np.random.shuffle(Data1_gloves)\n",
    "Data1_gloves = pd.DataFrame(Data1_gloves, columns=cols)\n",
    "\n",
    "f1_gloves = k_fold(Data1_gloves,1)\n",
    "f2_gloves = k_fold(Data1_gloves,2)\n",
    "f3_gloves = k_fold(Data1_gloves,3)\n",
    "f4_gloves = k_fold(Data1_gloves,4)\n",
    "f5_gloves = k_fold(Data1_gloves,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation results for different Learning rates and margin variables:\n",
      " Learning rate  Margin variable  accuracy mean  accuracy std\n",
      "        0.0100              0.2      64.466207      0.461541\n",
      "        0.0100              0.1      64.626233      0.317833\n",
      "        0.0500              0.2      64.123265      0.376297\n",
      "        0.0500              0.1      64.340476      0.635709\n",
      "        0.0010              0.2      64.414794      0.673248\n",
      "        0.0010              0.1      64.557679      0.594159\n",
      "        0.0001              0.2      63.660283      0.600437\n",
      "        0.0001              0.1      64.026148      0.865146\n",
      "Best learning rate: 0.01\n",
      "Best margin variable: 0.1\n",
      " Best learning rate  Best margin variable  Best accuracy\n",
      "               0.01                   0.1      64.626233\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the network accuracy based on different values for learning rates and u:\n",
    "\"\"\"\n",
    "The cross validation function in previous section is run for different values of learning rates to find the best\n",
    "hyper parameter\n",
    "\"\"\"\n",
    "Learning_rates = [ 0.01, 0.05, 0.001, 0.0001]\n",
    "margin_variable = [0.2,0.1]\n",
    "\n",
    "max_epoch = 10\n",
    "acc_mean = []\n",
    "acc_std = []\n",
    "result = []\n",
    "for lr in Learning_rates:\n",
    "    for u in margin_variable:\n",
    "        mean, std = cross_val_ev(f1_gloves, f2_gloves, f3_gloves, f4_gloves, f5_gloves, max_epoch, lr, 'margin_perceptron', u)\n",
    "        acc_mean.append(mean)\n",
    "        acc_std.append(std)\n",
    "        result.append([lr, u, mean, std])\n",
    "        #print(lr, u)\n",
    "\n",
    "result = np.array(result)\n",
    "Best_lr = result[np.argmax(result[:,2]), 0]\n",
    "Best_u = result[np.argmax(result[:,2]), 1]\n",
    "best_acc = result[np.argmax(result[:,2]), 2]\n",
    "\n",
    "print('Cross validation results for different Learning rates and margin variables:')\n",
    "result = pd.DataFrame(result, columns=['Learning rate', 'Margin variable', 'accuracy mean', 'accuracy std'])\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(result.to_string(index = False))\n",
    "print('Best learning rate:', Best_lr)\n",
    "\n",
    "print('Best margin variable:', Best_u)\n",
    "\n",
    "report1 = [{'Best learning rate':Best_lr, 'Best margin variable':Best_u, 'Best accuracy':best_acc}]\n",
    "report1 = pd.DataFrame.from_records(report1)\n",
    "print(report1.to_string(index = False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_epoch = 100\n",
    "w4, b4, ep_update4  = margin_perceptron(Train_data_glove, max_epoch, Best_lr, Best_u)\n",
    "#print(b)\n",
    "train_acc = []\n",
    "train_acc1 =[]\n",
    "acc = [ 0, 0, 0]\n",
    "for i in range (max_epoch):\n",
    "    #print(w[i][0])\n",
    "    train_acc.append (accuracy (Train_data_glove, w4[i][:],b4[i]))\n",
    "    acc[0] = i+1\n",
    "    acc[1] = accuracy (Train_data_glove, w4[i][:],b4[i])\n",
    "    acc[2] = ep_update4[i]\n",
    "    train_acc1.append(acc.copy())\n",
    "    \n",
    "#print(train_acc)\n",
    "\n",
    "train_acc = np.array(train_acc)\n",
    "\n",
    "best_epoch = np.argmax(train_acc)+1\n",
    "\n",
    "\n",
    "test_acc =  accuracy (Test_data_glove, w4[best_epoch-1][:],b4[best_epoch-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  Train accuracry  number of updates\n",
      "     1        65.468571               8053\n",
      "     2        65.942857              15771\n",
      "     3        66.068571              23663\n",
      "     4        66.005714              31663\n",
      "     5        66.160000              39889\n",
      "     6        66.360000              48396\n",
      "     7        66.491429              57113\n",
      "     8        66.571429              65876\n",
      "     9        66.611429              74773\n",
      "    10        66.760000              83908\n",
      "    11        66.737143              93210\n",
      "    12        66.760000             102624\n",
      "    13        66.725714             112250\n",
      "    14        66.737143             121885\n",
      "    15        66.731429             131677\n",
      "    16        66.714286             141466\n",
      "    17        66.731429             151545\n",
      "    18        66.754286             161593\n",
      "    19        66.731429             171591\n",
      "    20        66.760000             181842\n",
      "    21        66.800000             192122\n",
      "    22        66.794286             202483\n",
      "    23        66.782857             212970\n",
      "    24        66.777143             223463\n",
      "    25        66.788571             234015\n",
      "    26        66.817143             244640\n",
      "    27        66.805714             255324\n",
      "    28        66.811429             265974\n",
      "    29        66.811429             276748\n",
      "    30        66.777143             287645\n",
      "    31        66.765714             298598\n",
      "    32        66.765714             309462\n",
      "    33        66.777143             320405\n",
      "    34        66.771429             331521\n",
      "    35        66.788571             342536\n",
      "    36        66.788571             353565\n",
      "    37        66.811429             364714\n",
      "    38        66.828571             375888\n",
      "    39        66.834286             387041\n",
      "    40        66.840000             398265\n",
      "    41        66.834286             409450\n",
      "    42        66.874286             420815\n",
      "    43        66.851429             432142\n",
      "    44        66.845714             443430\n",
      "    45        66.840000             454843\n",
      "    46        66.840000             466199\n",
      "    47        66.840000             477613\n",
      "    48        66.828571             489025\n",
      "    49        66.840000             500482\n",
      "    50        66.817143             512026\n",
      "    51        66.828571             523498\n",
      "    52        66.840000             534960\n",
      "    53        66.857143             546589\n",
      "    54        66.880000             558084\n",
      "    55        66.862857             569630\n",
      "    56        66.874286             581238\n",
      "    57        66.845714             592873\n",
      "    58        66.857143             604475\n",
      "    59        66.874286             616082\n",
      "    60        66.874286             627750\n",
      "    61        66.862857             639468\n",
      "    62        66.874286             651215\n",
      "    63        66.897143             662989\n",
      "    64        66.902857             674701\n",
      "    65        66.897143             686490\n",
      "    66        66.920000             698221\n",
      "    67        66.914286             710022\n",
      "    68        66.920000             721863\n",
      "    69        66.920000             733698\n",
      "    70        66.908571             745525\n",
      "    71        66.914286             757412\n",
      "    72        66.908571             769303\n",
      "    73        66.908571             781126\n",
      "    74        66.891429             793023\n",
      "    75        66.880000             804940\n",
      "    76        66.891429             816897\n",
      "    77        66.885714             828806\n",
      "    78        66.897143             840689\n",
      "    79        66.902857             852713\n",
      "    80        66.891429             864650\n",
      "    81        66.891429             876681\n",
      "    82        66.902857             888657\n",
      "    83        66.885714             900626\n",
      "    84        66.868571             912709\n",
      "    85        66.880000             924760\n",
      "    86        66.880000             936797\n",
      "    87        66.857143             948758\n",
      "    88        66.845714             960828\n",
      "    89        66.845714             972947\n",
      "    90        66.851429             984913\n",
      "    91        66.851429             996963\n",
      "    92        66.851429            1009030\n",
      "    93        66.857143            1021125\n",
      "    94        66.857143            1033215\n",
      "    95        66.862857            1045365\n",
      "    96        66.862857            1057508\n",
      "    97        66.874286            1069640\n",
      "    98        66.891429            1081738\n",
      "    99        66.880000            1093900\n",
      "   100        66.874286            1106012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Training accuracy')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Epoch = np.arange(1,max_epoch+1)\n",
    "data2 = pd.DataFrame(train_acc1, columns=['Epoch','Train accuracry', 'number of updates'])\n",
    "print(data2.to_string(index = False))\n",
    "train_acc1 = np.array(train_acc1)\n",
    "plt.plot(train_acc1[:,0], train_acc1[:,1])\n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Training accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best learning rate  Best margin variable  Best cross val. acc.(%)  Best epoch  number of updates  Train accuracy(%)  Test accuracy(%)\n",
      "               0.01                   0.1                64.626233          66           698221.0              66.92         65.111111\n"
     ]
    }
   ],
   "source": [
    "report4 = [{'Best learning rate':Best_lr, 'Best margin variable':Best_u, 'Best cross val. acc.(%)':best_acc, \n",
    "            'Best epoch':best_epoch, 'number of updates':train_acc1[best_epoch-1][2],\n",
    "            'Train accuracy(%)':train_acc1[best_epoch-1][1], \n",
    "            'Test accuracy(%)':test_acc}]\n",
    "\n",
    "report4 = pd.DataFrame.from_records(report4)\n",
    "print(report4.to_string(index = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred4 = prediction (Eval_data_glove,  w4[best_epoch-1][:], b4[best_epoch-1])\n",
    "pred4.to_csv ('results\\Preceptron_result\\gloves_labels.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Margin perceptron with miscalleneous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating 5-fold dataset:\n",
    "Data1 = Train_misc\n",
    "cols = Data1.columns\n",
    "Data1 = Data1.to_numpy()\n",
    "np.random.shuffle(Data1)\n",
    "Data1 = pd.DataFrame(Data1, columns=cols)\n",
    "f1_misc = k_fold(Data1,1)\n",
    "f2_misc = k_fold(Data1,2)\n",
    "f3_misc = k_fold(Data1,3)\n",
    "f4_misc = k_fold(Data1,4)\n",
    "f5_misc = k_fold(Data1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation results for different Learning rates and margin variables:\n",
      " Learning rate  Margin variable  accuracy mean  accuracy std\n",
      "         1.000             1.00      78.275050      0.762655\n",
      "         1.000             0.10      77.612048      0.553744\n",
      "         1.000             0.01      77.749230      0.703646\n",
      "         0.100             1.00      78.469388      0.785687\n",
      "         0.100             0.10      78.200745      0.618433\n",
      "         0.100             0.01      77.766353      0.715318\n",
      "         0.010             1.00      78.183590      0.680370\n",
      "         0.010             0.10      78.457963      0.818276\n",
      "         0.010             0.01      78.183595      0.631128\n",
      "         0.001             1.00      77.977837      0.642310\n",
      "         0.001             0.10      78.177873      0.671491\n",
      "         0.001             0.01      78.446519      0.728204\n",
      "Best learning rate: 0.1\n",
      "Best margin variable: 1.0\n",
      " Best learning rate  Best margin variable  Best accuracy\n",
      "                0.1                   1.0      78.469388\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the network accuracy based on different values for learning rates and u:\n",
    "\"\"\"\n",
    "The cross validation function in previous section is run for different values of learning rates to find the best\n",
    "hyper parameter\n",
    "\"\"\"\n",
    "Learning_rates = [1,0.1, 0.01, 0.001]\n",
    "margin_variable = [1,0.1, 0.01]\n",
    "\n",
    "max_epoch = 10\n",
    "acc_mean = []\n",
    "acc_std = []\n",
    "result = []\n",
    "for lr in Learning_rates:\n",
    "    for u in margin_variable:\n",
    "        mean, std = cross_val_ev(f1_misc, f2_misc, f3_misc, f4_misc, f5_misc, max_epoch, lr, 'margin_perceptron', u)\n",
    "        acc_mean.append(mean)\n",
    "        acc_std.append(std)\n",
    "        result.append([lr, u, mean, std])\n",
    "        #print(lr, u)\n",
    "\n",
    "result = np.array(result)\n",
    "Best_lr = result[np.argmax(result[:,2]), 0]\n",
    "Best_u = result[np.argmax(result[:,2]), 1]\n",
    "best_acc = result[np.argmax(result[:,2]), 2]\n",
    "\n",
    "print('Cross validation results for different Learning rates and margin variables:')\n",
    "result = pd.DataFrame(result, columns=['Learning rate', 'Margin variable', 'accuracy mean', 'accuracy std'])\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(result.to_string(index = False))\n",
    "print('Best learning rate:', Best_lr)\n",
    "\n",
    "print('Best margin variable:', Best_u)\n",
    "\n",
    "report1 = [{'Best learning rate':Best_lr, 'Best margin variable':Best_u, 'Best accuracy':best_acc}]\n",
    "report1 = pd.DataFrame.from_records(report1)\n",
    "print(report1.to_string(index = False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_epoch = 80\n",
    "w4, b4, ep_update4  = margin_perceptron(Train_misc, max_epoch, Best_lr, Best_u)\n",
    "#print(b)\n",
    "train_acc = []\n",
    "train_acc1 =[]\n",
    "acc = [ 0, 0, 0]\n",
    "for i in range (max_epoch):\n",
    "    #print(w[i][0])\n",
    "    train_acc.append (accuracy (Train_misc, w4[i][:],b4[i]))\n",
    "    acc[0] = i+1\n",
    "    acc[1] = accuracy (Train_misc, w4[i][:],b4[i])\n",
    "    acc[2] = ep_update4[i]\n",
    "    train_acc1.append(acc.copy())\n",
    "    \n",
    "#print(train_acc)\n",
    "\n",
    "train_acc = np.array(train_acc)\n",
    "\n",
    "best_epoch = np.argmax(train_acc)+1\n",
    "\n",
    "\n",
    "test_acc =  accuracy (Test_misc, w4[best_epoch-1][:],b4[best_epoch-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  Train accuracry  number of updates\n",
      "     1        78.085714               7402\n",
      "     2        78.114286              14747\n",
      "     3        78.182857              22036\n",
      "     4        78.234286              29357\n",
      "     5        78.360000              36694\n",
      "     6        78.405714              44028\n",
      "     7        78.462857              51314\n",
      "     8        78.531429              58593\n",
      "     9        78.542857              65954\n",
      "    10        78.571429              73252\n",
      "    11        78.582857              80555\n",
      "    12        78.628571              87962\n",
      "    13        78.657143              95373\n",
      "    14        78.651429             102813\n",
      "    15        78.702857             110232\n",
      "    16        78.731429             117736\n",
      "    17        78.737143             125265\n",
      "    18        78.754286             132746\n",
      "    19        78.771429             140302\n",
      "    20        78.771429             147843\n",
      "    21        78.794286             155466\n",
      "    22        78.800000             163025\n",
      "    23        78.805714             170696\n",
      "    24        78.805714             178303\n",
      "    25        78.828571             185999\n",
      "    26        78.834286             193695\n",
      "    27        78.828571             201411\n",
      "    28        78.845714             209142\n",
      "    29        78.851429             216972\n",
      "    30        78.845714             224765\n",
      "    31        78.874286             232570\n",
      "    32        78.880000             240368\n",
      "    33        78.880000             248242\n",
      "    34        78.880000             256082\n",
      "    35        78.874286             264009\n",
      "    36        78.874286             272003\n",
      "    37        78.880000             279926\n",
      "    38        78.891429             287873\n",
      "    39        78.897143             295854\n",
      "    40        78.897143             303796\n",
      "    41        78.891429             311747\n",
      "    42        78.891429             319801\n",
      "    43        78.897143             327843\n",
      "    44        78.908571             335956\n",
      "    45        78.908571             344129\n",
      "    46        78.908571             352290\n",
      "    47        78.908571             360473\n",
      "    48        78.908571             368619\n",
      "    49        78.908571             376779\n",
      "    50        78.908571             384981\n",
      "    51        78.931429             393173\n",
      "    52        78.925714             401343\n",
      "    53        78.931429             409552\n",
      "    54        78.925714             417771\n",
      "    55        78.925714             425985\n",
      "    56        78.925714             434234\n",
      "    57        78.925714             442527\n",
      "    58        78.931429             450874\n",
      "    59        78.931429             459161\n",
      "    60        78.931429             467526\n",
      "    61        78.931429             475857\n",
      "    62        78.931429             484251\n",
      "    63        78.931429             492596\n",
      "    64        78.948571             500966\n",
      "    65        78.931429             509365\n",
      "    66        78.942857             517750\n",
      "    67        78.942857             526125\n",
      "    68        78.937143             534556\n",
      "    69        78.937143             542928\n",
      "    70        78.937143             551341\n",
      "    71        78.937143             559794\n",
      "    72        78.937143             568247\n",
      "    73        78.937143             576746\n",
      "    74        78.942857             585234\n",
      "    75        78.942857             593780\n",
      "    76        78.942857             602311\n",
      "    77        78.942857             610834\n",
      "    78        78.948571             619336\n",
      "    79        78.948571             627844\n",
      "    80        78.948571             636359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Training accuracy')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Epoch = np.arange(1,max_epoch+1)\n",
    "data2 = pd.DataFrame(train_acc1, columns=['Epoch','Train accuracry', 'number of updates'])\n",
    "print(data2.to_string(index = False))\n",
    "train_acc1 = np.array(train_acc1)\n",
    "plt.plot(train_acc1[:,0], train_acc1[:,1])\n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Training accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best learning rate  Best margin variable  Best cross val. acc.(%)  Best epoch  number of updates  Train accuracy(%)  Test accuracy(%)\n",
      "                0.1                   1.0                78.469388          64           500966.0          78.948571         79.466667\n"
     ]
    }
   ],
   "source": [
    "report4 = [{'Best learning rate':Best_lr, 'Best margin variable':Best_u, 'Best cross val. acc.(%)':best_acc, \n",
    "            'Best epoch':best_epoch, 'number of updates':train_acc1[best_epoch-1][2],\n",
    "            'Train accuracy(%)':train_acc1[best_epoch-1][1], \n",
    "            'Test accuracy(%)':test_acc}]\n",
    "\n",
    "report4 = pd.DataFrame.from_records(report4)\n",
    "print(report4.to_string(index = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred4 = prediction (Eval_misc,  w4[best_epoch-1][:], b4[best_epoch-1])\n",
    "pred4.to_csv ('results\\Preceptron_result\\misc_labels.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Margin perceptron with bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating 5-fold dataset:\n",
    "Data1 = Train_data_bow\n",
    "cols = Data1.columns\n",
    "Data1 = Data1.to_numpy()\n",
    "np.random.shuffle(Data1)\n",
    "Data1 = pd.DataFrame(Data1, columns=cols)\n",
    "f1 = k_fold(Data1,1)\n",
    "f2 = k_fold(Data1,2)\n",
    "f3 = k_fold(Data1,3)\n",
    "f4 = k_fold(Data1,4)\n",
    "f5 = k_fold(Data1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation results for different Learning rates and margin variables:\n",
      " Learning rate  Margin variable  accuracy mean  accuracy std\n",
      "         1.000             1.00      68.724277      0.590174\n",
      "         1.000             0.10      68.227017      0.461414\n",
      "         1.000             0.01      68.529926      0.805691\n",
      "         0.100             1.00      69.158649      0.590222\n",
      "         0.100             0.10      68.604227      0.425621\n",
      "         0.100             0.01      67.981239      0.337824\n",
      "         0.010             1.00      70.639012      0.586539\n",
      "         0.010             0.10      69.181511      0.795419\n",
      "         0.010             0.01      68.232693      0.483388\n",
      "         0.001             1.00      70.461843      0.727366\n",
      "         0.001             0.10      70.330382      0.585036\n",
      "         0.001             0.01      68.581392      0.224408\n",
      "Best learning rate: 0.01\n",
      "Best margin variable: 1.0\n",
      " Best learning rate  Best margin variable  Best accuracy\n",
      "               0.01                   1.0      70.639012\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the network accuracy based on different values for learning rates and u:\n",
    "\"\"\"\n",
    "The cross validation function in previous section is run for different values of learning rates to find the best\n",
    "hyper parameter\n",
    "\"\"\"\n",
    "Learning_rates = [1,0.1, 0.01, 0.001]\n",
    "margin_variable = [1,0.1, 0.01]\n",
    "\n",
    "max_epoch = 10\n",
    "acc_mean = []\n",
    "acc_std = []\n",
    "result = []\n",
    "for lr in Learning_rates:\n",
    "    for u in margin_variable:\n",
    "        mean, std = cross_val_ev(f1, f2, f3, f4, f5, max_epoch, lr, 'margin_perceptron', u)\n",
    "        acc_mean.append(mean)\n",
    "        acc_std.append(std)\n",
    "        result.append([lr, u, mean, std])\n",
    "        #print(lr, u)\n",
    "\n",
    "result = np.array(result)\n",
    "Best_lr = result[np.argmax(result[:,2]), 0]\n",
    "Best_u = result[np.argmax(result[:,2]), 1]\n",
    "best_acc = result[np.argmax(result[:,2]), 2]\n",
    "\n",
    "print('Cross validation results for different Learning rates and margin variables:')\n",
    "result = pd.DataFrame(result, columns=['Learning rate', 'Margin variable', 'accuracy mean', 'accuracy std'])\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(result.to_string(index = False))\n",
    "print('Best learning rate:', Best_lr)\n",
    "\n",
    "print('Best margin variable:', Best_u)\n",
    "\n",
    "report1 = [{'Best learning rate':Best_lr, 'Best margin variable':Best_u, 'Best accuracy':best_acc}]\n",
    "report1 = pd.DataFrame.from_records(report1)\n",
    "print(report1.to_string(index = False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 80\n",
    "w4, b4, ep_update4  = margin_perceptron(Train_data_bow, max_epoch, Best_lr, Best_u)\n",
    "#print(b)\n",
    "train_acc = []\n",
    "train_acc1 =[]\n",
    "acc = [ 0, 0, 0]\n",
    "for i in range (max_epoch):\n",
    "    #print(w[i][0])\n",
    "    train_acc.append (accuracy (Train_data_bow, w4[i][:],b4[i]))\n",
    "    acc[0] = i+1\n",
    "    acc[1] = accuracy (Train_data_bow, w4[i][:],b4[i])\n",
    "    acc[2] = ep_update4[i]\n",
    "    train_acc1.append(acc.copy())\n",
    "    \n",
    "#print(train_acc)\n",
    "\n",
    "train_acc = np.array(train_acc)\n",
    "\n",
    "best_epoch = np.argmax(train_acc)+1\n",
    "\n",
    "\n",
    "test_acc =  accuracy (Test_data_bow, w4[best_epoch-1][:],b4[best_epoch-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  Train accuracry  number of updates\n",
      "     1        73.754286               9814\n",
      "     2        76.520000              18113\n",
      "     3        78.251429              26146\n",
      "     4        79.097143              34084\n",
      "     5        80.017143              41855\n",
      "     6        80.708571              49574\n",
      "     7        81.245714              57227\n",
      "     8        81.708571              64853\n",
      "     9        82.074286              72467\n",
      "    10        82.388571              79986\n",
      "    11        82.668571              87452\n",
      "    12        83.034286              94915\n",
      "    13        83.257143             102378\n",
      "    14        83.382857             109833\n",
      "    15        83.634286             117187\n",
      "    16        83.725714             124557\n",
      "    17        83.862857             131931\n",
      "    18        83.971429             139251\n",
      "    19        84.068571             146537\n",
      "    20        84.154286             153818\n",
      "    21        84.274286             161077\n",
      "    22        84.434286             168313\n",
      "    23        84.588571             175537\n",
      "    24        84.685714             182763\n",
      "    25        84.765714             189983\n",
      "    26        84.834286             197197\n",
      "    27        84.925714             204421\n",
      "    28        84.982857             211571\n",
      "    29        85.028571             218756\n",
      "    30        85.108571             225900\n",
      "    31        85.154286             233045\n",
      "    32        85.217143             240176\n",
      "    33        85.245714             247262\n",
      "    34        85.297143             254345\n",
      "    35        85.331429             261441\n",
      "    36        85.371429             268554\n",
      "    37        85.417143             275676\n",
      "    38        85.457143             282764\n",
      "    39        85.485714             289799\n",
      "    40        85.491429             296852\n",
      "    41        85.537143             303907\n",
      "    42        85.571429             310960\n",
      "    43        85.628571             317975\n",
      "    44        85.714286             325021\n",
      "    45        85.748571             332053\n",
      "    46        85.777143             339095\n",
      "    47        85.822857             346078\n",
      "    48        85.822857             353099\n",
      "    49        85.834286             360101\n",
      "    50        85.851429             367095\n",
      "    51        85.880000             374115\n",
      "    52        85.920000             381107\n",
      "    53        85.937143             388041\n",
      "    54        85.977143             395000\n",
      "    55        86.040000             401972\n",
      "    56        86.057143             408947\n",
      "    57        86.068571             415861\n",
      "    58        86.102857             422838\n",
      "    59        86.120000             429786\n",
      "    60        86.131429             436718\n",
      "    61        86.137143             443696\n",
      "    62        86.165714             450623\n",
      "    63        86.177143             457515\n",
      "    64        86.200000             464397\n",
      "    65        86.188571             471328\n",
      "    66        86.205714             478262\n",
      "    67        86.205714             485184\n",
      "    68        86.194286             492095\n",
      "    69        86.222857             498964\n",
      "    70        86.257143             505849\n",
      "    71        86.285714             512711\n",
      "    72        86.320000             519619\n",
      "    73        86.337143             526512\n",
      "    74        86.354286             533389\n",
      "    75        86.377143             540232\n",
      "    76        86.394286             547100\n",
      "    77        86.400000             553985\n",
      "    78        86.411429             560852\n",
      "    79        86.428571             567730\n",
      "    80        86.434286             574583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Training accuracy')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Epoch = np.arange(1,max_epoch+1)\n",
    "data2 = pd.DataFrame(train_acc1, columns=['Epoch','Train accuracry', 'number of updates'])\n",
    "print(data2.to_string(index = False))\n",
    "train_acc1 = np.array(train_acc1)\n",
    "plt.plot(train_acc1[:,0], train_acc1[:,1])\n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Training accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best learning rate  Best margin variable  Best cross val. acc.(%)  Best epoch  number of updates  Train accuracy(%)  Test accuracy(%)\n",
      "               0.01                   1.0                70.639012          80           574583.0          86.434286         71.244444\n"
     ]
    }
   ],
   "source": [
    "report4 = [{'Best learning rate':Best_lr, 'Best margin variable':Best_u, 'Best cross val. acc.(%)':best_acc, \n",
    "            'Best epoch':best_epoch, 'number of updates':train_acc1[best_epoch-1][2],\n",
    "            'Train accuracy(%)':train_acc1[best_epoch-1][1], \n",
    "            'Test accuracy(%)':test_acc}]\n",
    "\n",
    "report4 = pd.DataFrame.from_records(report4)\n",
    "print(report4.to_string(index = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred4 = prediction (Eval_data_bow,  w4[best_epoch-1][:], b4[best_epoch-1])\n",
    "pred4.to_csv ('bow_labels.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Margin perceptron with tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating 5-fold dataset:\n",
    "Data1 = Train_data_tfidf\n",
    "cols = Data1.columns\n",
    "Data1 = Data1.to_numpy()\n",
    "np.random.shuffle(Data1)\n",
    "Data1 = pd.DataFrame(Data1, columns=cols)\n",
    "f1 = k_fold(Data1,1)\n",
    "f2 = k_fold(Data1,2)\n",
    "f3 = k_fold(Data1,3)\n",
    "f4 = k_fold(Data1,4)\n",
    "f5 = k_fold(Data1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation results for different Learning rates and margin variables:\n",
      " Learning rate  Margin variable  accuracy mean  accuracy std\n",
      "         1.000             1.00      71.284890      0.443860\n",
      "         1.000             0.10      70.147487      0.374806\n",
      "         1.000             0.01      69.936036      0.502691\n",
      "         0.100             1.00      71.867907      0.636873\n",
      "         0.100             0.10      71.599239      0.264732\n",
      "         0.100             0.01      69.838847      0.371118\n",
      "         0.010             1.00      67.844184      1.132475\n",
      "         0.010             0.10      71.930798      0.784060\n",
      "         0.010             0.01      70.953412      0.522366\n",
      "         0.001             1.00      52.679993      5.426802\n",
      "         0.001             0.10      68.044222      1.294163\n",
      "         0.001             0.01      69.758850      0.635772\n",
      "Best learning rate: 0.01\n",
      "Best margin variable: 0.1\n",
      " Best learning rate  Best margin variable  Best accuracy\n",
      "               0.01                   0.1      71.930798\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the network accuracy based on different values for learning rates and u:\n",
    "\"\"\"\n",
    "The cross validation function in previous section is run for different values of learning rates to find the best\n",
    "hyper parameter\n",
    "\"\"\"\n",
    "Learning_rates = [1,0.1, 0.01, 0.001]\n",
    "margin_variable = [1,0.1, 0.01]\n",
    "\n",
    "max_epoch = 10\n",
    "acc_mean = []\n",
    "acc_std = []\n",
    "result = []\n",
    "for lr in Learning_rates:\n",
    "    for u in margin_variable:\n",
    "        mean, std = cross_val_ev(f1, f2, f3, f4, f5, max_epoch, lr, 'margin_perceptron', u)\n",
    "        acc_mean.append(mean)\n",
    "        acc_std.append(std)\n",
    "        result.append([lr, u, mean, std])\n",
    "        #print(lr, u)\n",
    "\n",
    "result = np.array(result)\n",
    "Best_lr = result[np.argmax(result[:,2]), 0]\n",
    "Best_u = result[np.argmax(result[:,2]), 1]\n",
    "best_acc = result[np.argmax(result[:,2]), 2]\n",
    "\n",
    "print('Cross validation results for different Learning rates and margin variables:')\n",
    "result = pd.DataFrame(result, columns=['Learning rate', 'Margin variable', 'accuracy mean', 'accuracy std'])\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(result.to_string(index = False))\n",
    "print('Best learning rate:', Best_lr)\n",
    "\n",
    "print('Best margin variable:', Best_u)\n",
    "\n",
    "report1 = [{'Best learning rate':Best_lr, 'Best margin variable':Best_u, 'Best accuracy':best_acc}]\n",
    "report1 = pd.DataFrame.from_records(report1)\n",
    "print(report1.to_string(index = False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 80\n",
    "w4, b4, ep_update4  = margin_perceptron(Train_data_tfidf, max_epoch, Best_lr, Best_u)\n",
    "#print(b)\n",
    "train_acc = []\n",
    "train_acc1 =[]\n",
    "acc = [ 0, 0, 0]\n",
    "for i in range (max_epoch):\n",
    "    #print(w[i][0])\n",
    "    train_acc.append (accuracy (Train_data_tfidf, w4[i][:],b4[i]))\n",
    "    acc[0] = i+1\n",
    "    acc[1] = accuracy (Train_data_tfidf, w4[i][:],b4[i])\n",
    "    acc[2] = ep_update4[i]\n",
    "    train_acc1.append(acc.copy())\n",
    "    \n",
    "#print(train_acc)\n",
    "\n",
    "train_acc = np.array(train_acc)\n",
    "\n",
    "best_epoch = np.argmax(train_acc)+1\n",
    "\n",
    "\n",
    "test_acc =  accuracy (Test_data_tfidf, w4[best_epoch-1][:],b4[best_epoch-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  Train accuracry  number of updates\n",
      "     1        73.485714              14450\n",
      "     2        75.222857              26805\n",
      "     3        76.034286              38674\n",
      "     4        76.611429              50224\n",
      "     5        77.062857              61554\n",
      "     6        77.554286              72823\n",
      "     7        77.937143              83974\n",
      "     8        78.182857              94996\n",
      "     9        78.371429             105986\n",
      "    10        78.451429             116906\n",
      "    11        78.657143             127773\n",
      "    12        78.714286             138604\n",
      "    13        78.828571             149383\n",
      "    14        78.982857             160107\n",
      "    15        79.091429             170779\n",
      "    16        79.160000             181418\n",
      "    17        79.274286             192057\n",
      "    18        79.365714             202657\n",
      "    19        79.457143             213214\n",
      "    20        79.502857             223767\n",
      "    21        79.582857             234291\n",
      "    22        79.662857             244789\n",
      "    23        79.702857             255269\n",
      "    24        79.760000             265735\n",
      "    25        79.845714             276188\n",
      "    26        79.868571             286615\n",
      "    27        79.908571             297053\n",
      "    28        79.982857             307450\n",
      "    29        79.988571             317836\n",
      "    30        80.045714             328193\n",
      "    31        80.091429             338555\n",
      "    32        80.108571             348915\n",
      "    33        80.120000             359240\n",
      "    34        80.154286             369575\n",
      "    35        80.165714             379867\n",
      "    36        80.188571             390173\n",
      "    37        80.234286             400468\n",
      "    38        80.240000             410730\n",
      "    39        80.280000             420984\n",
      "    40        80.308571             431252\n",
      "    41        80.314286             441502\n",
      "    42        80.342857             451738\n",
      "    43        80.365714             461970\n",
      "    44        80.394286             472198\n",
      "    45        80.411429             482410\n",
      "    46        80.417143             492604\n",
      "    47        80.428571             502797\n",
      "    48        80.434286             512969\n",
      "    49        80.462857             523122\n",
      "    50        80.480000             533290\n",
      "    51        80.485714             543455\n",
      "    52        80.514286             553601\n",
      "    53        80.537143             563743\n",
      "    54        80.520000             573887\n",
      "    55        80.560000             583999\n",
      "    56        80.565714             594102\n",
      "    57        80.605714             604214\n",
      "    58        80.605714             614326\n",
      "    59        80.634286             624394\n",
      "    60        80.640000             634470\n",
      "    61        80.645714             644550\n",
      "    62        80.645714             654600\n",
      "    63        80.680000             664659\n",
      "    64        80.685714             674744\n",
      "    65        80.697143             684801\n",
      "    66        80.714286             694832\n",
      "    67        80.731429             704859\n",
      "    68        80.742857             714885\n",
      "    69        80.754286             724925\n",
      "    70        80.765714             734961\n",
      "    71        80.794286             744998\n",
      "    72        80.800000             755015\n",
      "    73        80.811429             765035\n",
      "    74        80.822857             775039\n",
      "    75        80.840000             785034\n",
      "    76        80.845714             795022\n",
      "    77        80.845714             805024\n",
      "    78        80.851429             815006\n",
      "    79        80.880000             824961\n",
      "    80        80.885714             834932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Training accuracy')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Epoch = np.arange(1,max_epoch+1)\n",
    "data2 = pd.DataFrame(train_acc1, columns=['Epoch','Train accuracry', 'number of updates'])\n",
    "print(data2.to_string(index = False))\n",
    "train_acc1 = np.array(train_acc1)\n",
    "plt.plot(train_acc1[:,0], train_acc1[:,1])\n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Training accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best learning rate  Best margin variable  Best cross val. acc.(%)  Best epoch  number of updates  Train accuracy(%)  Test accuracy(%)\n",
      "               0.01                   0.1                71.930798          80           834932.0          80.885714         72.844444\n"
     ]
    }
   ],
   "source": [
    "report4 = [{'Best learning rate':Best_lr, 'Best margin variable':Best_u, 'Best cross val. acc.(%)':best_acc, \n",
    "            'Best epoch':best_epoch, 'number of updates':train_acc1[best_epoch-1][2],\n",
    "            'Train accuracy(%)':train_acc1[best_epoch-1][1], \n",
    "            'Test accuracy(%)':test_acc}]\n",
    "\n",
    "report4 = pd.DataFrame.from_records(report4)\n",
    "print(report4.to_string(index = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred4 = prediction (Eval_data_tfidf,  w4[best_epoch-1][:], b4[best_epoch-1])\n",
    "pred4.to_csv ('tfidf_labels.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Margin perceptron with miscalleneous+tfidf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data = concat_datasets(Train_misc, Train_data_tfidf)\n",
    "Test_data = concat_datasets(Test_misc, Test_data_tfidf)\n",
    "Eval_data = concat_datasets(Eval_misc, Eval_data_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating 5-fold dataset:\n",
    "Data1 = Train_data\n",
    "cols = Data1.columns\n",
    "Data1 = Data1.to_numpy()\n",
    "np.random.shuffle(Data1)\n",
    "Data1 = pd.DataFrame(Data1, columns=cols)\n",
    "f1_misc = k_fold(Data1,1)\n",
    "f2_misc = k_fold(Data1,2)\n",
    "f3_misc = k_fold(Data1,3)\n",
    "f4_misc = k_fold(Data1,4)\n",
    "f5_misc = k_fold(Data1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation results for different Learning rates and margin variables:\n",
      " Learning rate  Margin variable  accuracy mean  accuracy std\n",
      "         1.000              1.0      79.743953      0.376533\n",
      "         1.000              0.5      79.195274      0.538384\n",
      "         1.000              0.1      78.892333      0.590322\n",
      "         0.100              1.0      80.921352      0.657139\n",
      "         0.100              0.5      80.978528      0.655068\n",
      "         0.100              0.1      79.789682      0.570851\n",
      "         0.010              1.0      78.263636      0.748778\n",
      "         0.010              0.5      78.640866      0.841444\n",
      "         0.010              0.1      80.864196      0.594491\n",
      "         0.001              1.0      77.989288      0.695541\n",
      "         0.001              0.5      78.040728      0.735774\n",
      "         0.001              0.1      78.303649      0.784628\n",
      "Best learning rate: 0.1\n",
      "Best margin variable: 0.5\n",
      " Best learning rate  Best margin variable  Best accuracy\n",
      "                0.1                   0.5      80.978528\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the network accuracy based on different values for learning rates and u:\n",
    "\"\"\"\n",
    "The cross validation function in previous section is run for different values of learning rates to find the best\n",
    "hyper parameter\n",
    "\"\"\"\n",
    "Learning_rates = [1,0.1, 0.01, 0.001]\n",
    "margin_variable = [1,0.5, 0.1]\n",
    "\n",
    "max_epoch = 10\n",
    "acc_mean = []\n",
    "acc_std = []\n",
    "result = []\n",
    "for lr in Learning_rates:\n",
    "    for u in margin_variable:\n",
    "        mean, std = cross_val_ev(f1_misc, f2_misc, f3_misc, f4_misc, f5_misc, max_epoch, lr, 'margin_perceptron', u)\n",
    "        acc_mean.append(mean)\n",
    "        acc_std.append(std)\n",
    "        result.append([lr, u, mean, std])\n",
    "        #print(lr, u)\n",
    "\n",
    "result = np.array(result)\n",
    "Best_lr = result[np.argmax(result[:,2]), 0]\n",
    "Best_u = result[np.argmax(result[:,2]), 1]\n",
    "best_acc = result[np.argmax(result[:,2]), 2]\n",
    "\n",
    "print('Cross validation results for different Learning rates and margin variables:')\n",
    "result = pd.DataFrame(result, columns=['Learning rate', 'Margin variable', 'accuracy mean', 'accuracy std'])\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(result.to_string(index = False))\n",
    "print('Best learning rate:', Best_lr)\n",
    "\n",
    "print('Best margin variable:', Best_u)\n",
    "\n",
    "report1 = [{'Best learning rate':Best_lr, 'Best margin variable':Best_u, 'Best accuracy':best_acc}]\n",
    "report1 = pd.DataFrame.from_records(report1)\n",
    "print(report1.to_string(index = False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 100\n",
    "w4, b4, ep_update4  = margin_perceptron(Train_data, max_epoch, Best_lr, Best_u)\n",
    "#print(b)\n",
    "train_acc = []\n",
    "train_acc1 =[]\n",
    "acc = [ 0, 0, 0]\n",
    "for i in range (max_epoch):\n",
    "    #print(w[i][0])\n",
    "    train_acc.append (accuracy (Train_data, w4[i][:],b4[i]))\n",
    "    acc[0] = i+1\n",
    "    acc[1] = accuracy (Train_data, w4[i][:],b4[i])\n",
    "    acc[2] = ep_update4[i]\n",
    "    train_acc1.append(acc.copy())\n",
    "    \n",
    "#print(train_acc)\n",
    "\n",
    "train_acc = np.array(train_acc)\n",
    "\n",
    "best_epoch = np.argmax(train_acc)+1\n",
    "\n",
    "\n",
    "test_acc =  accuracy (Test_data, w4[best_epoch-1][:],b4[best_epoch-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  Train accuracry  number of updates\n",
      "     1        79.634286               6662\n",
      "     2        81.240000              13047\n",
      "     3        81.851429              19153\n",
      "     4        82.354286              25161\n",
      "     5        82.857143              31044\n",
      "     6        83.274286              36877\n",
      "     7        83.451429              42566\n",
      "     8        83.628571              48269\n",
      "     9        83.720000              53951\n",
      "    10        83.885714              59543\n",
      "    11        84.028571              65185\n",
      "    12        84.102857              70743\n",
      "    13        84.194286              76290\n",
      "    14        84.245714              81831\n",
      "    15        84.354286              87378\n",
      "    16        84.400000              92893\n",
      "    17        84.520000              98424\n",
      "    18        84.588571             103913\n",
      "    19        84.674286             109402\n",
      "    20        84.714286             114915\n",
      "    21        84.760000             120366\n",
      "    22        84.811429             125819\n",
      "    23        84.857143             131321\n",
      "    24        84.908571             136764\n",
      "    25        84.948571             142155\n",
      "    26        85.022857             147566\n",
      "    27        85.062857             152937\n",
      "    28        85.120000             158368\n",
      "    29        85.142857             163802\n",
      "    30        85.200000             169250\n",
      "    31        85.240000             174673\n",
      "    32        85.268571             180045\n",
      "    33        85.291429             185451\n",
      "    34        85.297143             190821\n",
      "    35        85.320000             196235\n",
      "    36        85.394286             201654\n",
      "    37        85.428571             207101\n",
      "    38        85.502857             212500\n",
      "    39        85.537143             217833\n",
      "    40        85.560000             223221\n",
      "    41        85.588571             228681\n",
      "    42        85.622857             234109\n",
      "    43        85.634286             239491\n",
      "    44        85.668571             244901\n",
      "    45        85.702857             250336\n",
      "    46        85.737143             255645\n",
      "    47        85.782857             261053\n",
      "    48        85.794286             266486\n",
      "    49        85.800000             271877\n",
      "    50        85.805714             277307\n",
      "    51        85.857143             282682\n",
      "    52        85.897143             287999\n",
      "    53        85.908571             293317\n",
      "    54        85.920000             298730\n",
      "    55        85.982857             304142\n",
      "    56        86.000000             309506\n",
      "    57        86.000000             314925\n",
      "    58        86.028571             320345\n",
      "    59        86.028571             325722\n",
      "    60        86.045714             331126\n",
      "    61        86.085714             336504\n",
      "    62        86.125714             341876\n",
      "    63        86.125714             347230\n",
      "    64        86.137143             352594\n",
      "    65        86.154286             357972\n",
      "    66        86.194286             363332\n",
      "    67        86.194286             368741\n",
      "    68        86.205714             374126\n",
      "    69        86.217143             379524\n",
      "    70        86.257143             384961\n",
      "    71        86.297143             390371\n",
      "    72        86.325714             395756\n",
      "    73        86.342857             401118\n",
      "    74        86.394286             406505\n",
      "    75        86.411429             411930\n",
      "    76        86.445714             417330\n",
      "    77        86.480000             422685\n",
      "    78        86.480000             428061\n",
      "    79        86.497143             433460\n",
      "    80        86.514286             438908\n",
      "    81        86.537143             444314\n",
      "    82        86.537143             449737\n",
      "    83        86.560000             455147\n",
      "    84        86.560000             460491\n",
      "    85        86.571429             465839\n",
      "    86        86.600000             471195\n",
      "    87        86.611429             476612\n",
      "    88        86.657143             481977\n",
      "    89        86.691429             487324\n",
      "    90        86.685714             492715\n",
      "    91        86.702857             498051\n",
      "    92        86.725714             503461\n",
      "    93        86.748571             508821\n",
      "    94        86.760000             514189\n",
      "    95        86.760000             519571\n",
      "    96        86.788571             524994\n",
      "    97        86.800000             530414\n",
      "    98        86.800000             535808\n",
      "    99        86.817143             541186\n",
      "   100        86.817143             546554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Training accuracy')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Epoch = np.arange(1,max_epoch+1)\n",
    "data2 = pd.DataFrame(train_acc1, columns=['Epoch','Train accuracry', 'number of updates'])\n",
    "print(data2.to_string(index = False))\n",
    "train_acc1 = np.array(train_acc1)\n",
    "plt.plot(train_acc1[:,0], train_acc1[:,1])\n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Training accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best learning rate  Best margin variable  Best cross val. acc.(%)  Best epoch  number of updates  Train accuracy(%)  Test accuracy(%)\n",
      "                0.1                   0.5                80.978528          99           541186.0          86.817143         82.355556\n"
     ]
    }
   ],
   "source": [
    "report4 = [{'Best learning rate':Best_lr, 'Best margin variable':Best_u, 'Best cross val. acc.(%)':best_acc, \n",
    "            'Best epoch':best_epoch, 'number of updates':train_acc1[best_epoch-1][2],\n",
    "            'Train accuracy(%)':train_acc1[best_epoch-1][1], \n",
    "            'Test accuracy(%)':test_acc}]\n",
    "\n",
    "report4 = pd.DataFrame.from_records(report4)\n",
    "print(report4.to_string(index = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred4 = prediction (Eval_data,  w4[best_epoch-1][:], b4[best_epoch-1])\n",
    "pred4.to_csv ('misc_tfidf_labels.csv', index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
